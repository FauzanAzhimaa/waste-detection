{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üóëÔ∏è YOLOv8 Waste Detection Training\n",
    "## Kampus 1 UNJANI Yogyakarta - Object Detection\n",
    "\n",
    "**Dataset**: Roboflow garbage_best (3485 train, 487 test images)\n",
    "\n",
    "**Model**: YOLOv8 Nano (lightweight untuk deployment)\n",
    "\n",
    "**Output**: Bounding boxes untuk deteksi lokasi sampah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ultralytics YOLOv8\n",
    "!pip install ultralytics roboflow -q\n",
    "\n",
    "# Import libraries\n",
    "from ultralytics import YOLO\n",
    "from roboflow import Roboflow\n",
    "import os\n",
    "from pathlib import Path\n",
    "from google.colab import drive\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 2: Mount Google Drive (Optional - untuk save model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive untuk save model\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('/content/drive/MyDrive/waste-detection-yolo')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 3: Download Dataset dari Roboflow\n",
    "\n",
    "**IMPORTANT**: Ganti `YOUR_API_KEY` dengan API key dari Roboflow!\n",
    "\n",
    "Cara dapat API key:\n",
    "1. Login ke Roboflow\n",
    "2. Klik profile ‚Üí Settings ‚Üí API Key\n",
    "3. Copy paste ke cell di bawah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset dari Roboflow\n",
    "# ‚ö†Ô∏è GANTI 'YOUR_API_KEY' dengan API key kamu dari Roboflow!\n",
    "\n",
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
    "project = rf.workspace(\"smart-india-hackathon-2023\").project(\"garbage_best\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n",
    "\n",
    "print(f\"‚úÖ Dataset downloaded to: {dataset.location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 4: Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset structure\n",
    "import yaml\n",
    "\n",
    "data_yaml = Path(dataset.location) / 'data.yaml'\n",
    "\n",
    "with open(data_yaml, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"üìä Dataset Configuration:\")\n",
    "print(f\"  Train images: {data_config.get('train', 'N/A')}\")\n",
    "print(f\"  Val images: {data_config.get('val', 'N/A')}\")\n",
    "print(f\"  Test images: {data_config.get('test', 'N/A')}\")\n",
    "print(f\"  Classes: {data_config.get('names', [])}\")\n",
    "print(f\"  Number of classes: {data_config.get('nc', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 5: Train YOLOv8 Model\n",
    "\n",
    "**Model Options**:\n",
    "- `yolov8n.pt` - Nano (fastest, smallest) ‚úÖ RECOMMENDED\n",
    "- `yolov8s.pt` - Small\n",
    "- `yolov8m.pt` - Medium\n",
    "- `yolov8l.pt` - Large\n",
    "- `yolov8x.pt` - Extra Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLOv8 Nano model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Training parameters\n",
    "results = model.train(\n",
    "    data=str(data_yaml),\n",
    "    epochs=100,              # Jumlah epoch (bisa dikurangi jadi 50 untuk cepat)\n",
    "    imgsz=640,               # Image size\n",
    "    batch=16,                # Batch size (kurangi jika OOM)\n",
    "    name='waste_detection',  # Experiment name\n",
    "    patience=20,             # Early stopping patience\n",
    "    save=True,               # Save checkpoints\n",
    "    device=0,                # GPU device (0 = first GPU)\n",
    "    workers=2,               # Number of workers\n",
    "    project='runs/detect',   # Project directory\n",
    "    exist_ok=True,           # Overwrite existing\n",
    "    pretrained=True,         # Use pretrained weights\n",
    "    optimizer='auto',        # Optimizer\n",
    "    verbose=True,            # Verbose output\n",
    "    seed=42,                 # Random seed\n",
    "    deterministic=True,      # Deterministic mode\n",
    "    single_cls=False,        # Multi-class detection\n",
    "    rect=False,              # Rectangular training\n",
    "    cos_lr=False,            # Cosine LR scheduler\n",
    "    close_mosaic=10,         # Disable mosaic augmentation for final epochs\n",
    "    resume=False,            # Resume training\n",
    "    amp=True,                # Automatic Mixed Precision\n",
    "    fraction=1.0,            # Dataset fraction to train on\n",
    "    profile=False,           # Profile ONNX and TensorRT speeds\n",
    "    freeze=None,             # Freeze layers\n",
    "    lr0=0.01,                # Initial learning rate\n",
    "    lrf=0.01,                # Final learning rate\n",
    "    momentum=0.937,          # SGD momentum\n",
    "    weight_decay=0.0005,     # Optimizer weight decay\n",
    "    warmup_epochs=3.0,       # Warmup epochs\n",
    "    warmup_momentum=0.8,     # Warmup momentum\n",
    "    warmup_bias_lr=0.1,      # Warmup bias learning rate\n",
    "    box=7.5,                 # Box loss gain\n",
    "    cls=0.5,                 # Class loss gain\n",
    "    dfl=1.5,                 # DFL loss gain\n",
    "    pose=12.0,               # Pose loss gain\n",
    "    kobj=1.0,                # Keypoint obj loss gain\n",
    "    label_smoothing=0.0,     # Label smoothing\n",
    "    nbs=64,                  # Nominal batch size\n",
    "    hsv_h=0.015,             # HSV-Hue augmentation\n",
    "    hsv_s=0.7,               # HSV-Saturation augmentation\n",
    "    hsv_v=0.4,               # HSV-Value augmentation\n",
    "    degrees=0.0,             # Rotation augmentation\n",
    "    translate=0.1,           # Translation augmentation\n",
    "    scale=0.5,               # Scale augmentation\n",
    "    shear=0.0,               # Shear augmentation\n",
    "    perspective=0.0,         # Perspective augmentation\n",
    "    flipud=0.0,              # Flip up-down augmentation\n",
    "    fliplr=0.5,              # Flip left-right augmentation\n",
    "    mosaic=1.0,              # Mosaic augmentation\n",
    "    mixup=0.0,               # Mixup augmentation\n",
    "    copy_paste=0.0,          # Copy-paste augmentation\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 6: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate model on test set\n",
    "metrics = model.val()\n",
    "\n",
    "print(\"\\nüìä Model Performance:\")\n",
    "print(f\"  mAP50: {metrics.box.map50:.3f}\")\n",
    "print(f\"  mAP50-95: {metrics.box.map:.3f}\")\n",
    "print(f\"  Precision: {metrics.box.mp:.3f}\")\n",
    "print(f\"  Recall: {metrics.box.mr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Step 7: Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on sample images\n",
    "test_images = list(Path(dataset.location).glob('test/images/*.jpg'))[:5]\n",
    "\n",
    "for img_path in test_images:\n",
    "    results = model.predict(str(img_path), conf=0.25)\n",
    "    \n",
    "    # Display results\n",
    "    for r in results:\n",
    "        print(f\"\\nüì∏ Image: {img_path.name}\")\n",
    "        print(f\"  Detected {len(r.boxes)} objects\")\n",
    "        \n",
    "        # Show image with boxes\n",
    "        import matplotlib.pyplot as plt\n",
    "        from PIL import Image\n",
    "        \n",
    "        img_with_boxes = r.plot()\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img_with_boxes)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"{img_path.name} - {len(r.boxes)} objects detected\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 8: Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model path\n",
    "best_model_path = Path('runs/detect/waste_detection/weights/best.pt')\n",
    "\n",
    "# Copy to Google Drive\n",
    "import shutil\n",
    "\n",
    "drive_model_path = output_dir / 'waste_yolo_best.pt'\n",
    "shutil.copy(best_model_path, drive_model_path)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {drive_model_path}\")\n",
    "print(f\"\\nüì¶ Model size: {drive_model_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Also save to Colab for download\n",
    "colab_model_path = Path('/content/waste_yolo_best.pt')\n",
    "shutil.copy(best_model_path, colab_model_path)\n",
    "\n",
    "print(f\"\\nüì• Download model from: {colab_model_path}\")\n",
    "print(\"   (Klik kanan di file browser ‚Üí Download)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 9: View Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves\n",
    "from IPython.display import Image, display\n",
    "\n",
    "results_dir = Path('runs/detect/waste_detection')\n",
    "\n",
    "print(\"üìä Training Results:\")\n",
    "\n",
    "# Results plot\n",
    "if (results_dir / 'results.png').exists():\n",
    "    display(Image(filename=str(results_dir / 'results.png')))\n",
    "\n",
    "# Confusion matrix\n",
    "if (results_dir / 'confusion_matrix.png').exists():\n",
    "    print(\"\\nüéØ Confusion Matrix:\")\n",
    "    display(Image(filename=str(results_dir / 'confusion_matrix.png')))\n",
    "\n",
    "# PR curve\n",
    "if (results_dir / 'PR_curve.png').exists():\n",
    "    print(\"\\nüìà Precision-Recall Curve:\")\n",
    "    display(Image(filename=str(results_dir / 'PR_curve.png')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 10: Model Info & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üéâ YOLOv8 Training Completed!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüì¶ Model Files:\")\n",
    "print(f\"  Best model: {best_model_path}\")\n",
    "print(f\"  Google Drive: {drive_model_path}\")\n",
    "print(f\"  Download: {colab_model_path}\")\n",
    "print(\"\\nüìä Performance:\")\n",
    "print(f\"  mAP50: {metrics.box.map50:.3f}\")\n",
    "print(f\"  mAP50-95: {metrics.box.map:.3f}\")\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"  1. Download model: waste_yolo_best.pt\")\n",
    "print(\"  2. Copy to project: models/waste_yolo_best.pt\")\n",
    "print(\"  3. Update app.py untuk integrasi YOLO\")\n",
    "print(\"  4. Test inference di localhost\")\n",
    "print(\"  5. Deploy ke server\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
